{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b93f83-c7f5-4061-8efa-2b66ee03dc65",
   "metadata": {},
   "source": [
    "##### Algorithms and Data Structures (Winter - Spring 2022)\n",
    "\n",
    "* [Colab view](https://colab.research.google.com/github/4dsolutions/elite_school/blob/master/ADS_research_1.ipynb)\n",
    "* [nbviewer view](https://nbviewer.org/github/4dsolutions/elite_school/blob/master/ADS_research_1.ipynb)\n",
    "* [ADS Page 1](ADS_intro_1.ipynb)\n",
    "* [ADS Page 2](ADS_intro_2.ipynb)\n",
    "* [ACSL](Exercises.ipynb)\n",
    "* [Repo](https://github.com/4dsolutions/elite_school/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00c0d1-9060-4179-8a06-92bc19f1008f",
   "metadata": {},
   "source": [
    "## Five Letter Land:  A Semantic Space\n",
    "\n",
    "Around the time of our *Algorithms and Data Structures* first meetups, [the word game Wordle](ADS_project_1.ipynb) became popular.  \n",
    "\n",
    "The focus of the game is accepted English dictionary words of five letters. Of course the rules could be extended or refocused. Our research went with that definition and particular data file structured as text:\n",
    "\n",
    "https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\n",
    "(don't click the link unless you wish to eyeball the file)\n",
    "\n",
    "Beginning with exactly this list of 5-letter words, we embarked upon some research adventures bringing in our sense of Graph Theory.  The words are nodes and we consider them connected by an edge if they are one and only one letter different.\n",
    "\n",
    "For example, neighbors of \"caked\" would be \"naked\" and \"baked\".  We will need an algorithm that gives us a complete list of neighbors.\n",
    "\n",
    "Example research questions:\n",
    "\n",
    "* given \"only one letter different\" defines an edge between words, does our net of connected words encompass all the words?\n",
    "\n",
    "* if the answer to the above question is \"no\" then does the set consist of \"islands\" of words with definite boundaries?\n",
    "\n",
    "But first, we need the set of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ffe7d0-b89c-412e-bbcb-c19ed161bb5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\")\n",
    "print(response.status_code)\n",
    "# words\n",
    "words = set(response.text.split(\"\\n\")) # <-- linebreak delimited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb0df5-4099-43e7-a284-f06d7156f7a8",
   "metadata": {},
   "source": [
    "The classroom toolkit includes Replits in the Cloud.  We welcome a \"many languages\" approach.  C++, Julia... Replits come in many flavors.\n",
    "\n",
    "Through Replits ([example](https://replit.com/@kurner/fiveland#main.py)), we might use Python only because requests is so convenient and the Replit makes it easy to install as a package.  Once we harvest our data, we might switch to some other language or tool.  It's up to us to design the pipelines.\n",
    "\n",
    "Having done the work to retrieve the text file from [The Stanford Graphbase](https://www-cs-faculty.stanford.edu/~knuth/sgb.html), why not keep it locally.  It's a tiny file, but requesting it over the internet everytime requires unnecessary dependency and overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a05060-845b-4d53-8180-63a03cd70618",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wordkeep.txt\",\"w\") as the_file:\n",
    "    the_file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f271d470-4251-4d2a-a6a4-7504044d540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which\n",
      "there\n",
      "their\n",
      "about\n",
      "would\n",
      "these\n",
      "other\n",
      "words\n",
      "could\n",
      "write\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "if not os.path.exists(\"./wordkeep.txt\"):\n",
    "    print(\"No wordkeep.txt on file\")\n",
    "\n",
    "else:\n",
    "\n",
    "    with open(\"wordkeep.txt\",\"r\") as the_file:\n",
    "        for _ in range(10):\n",
    "            print(the_file.readline(), end=\"\")\n",
    "\n",
    "    if not \"words\" in globals():\n",
    "        with open(\"wordkeep.txt\",\"r\") as the_file:\n",
    "            words = set(the_file.read().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5faa3a-e4b0-47fd-a1c5-883e55ed616b",
   "metadata": {},
   "source": [
    "Lets continue our work in Python because of its set type, which will give us fast lookup and prevent inadvertent duplication as a built-in feature.  Sets do not allow duplicates.  As we find all words reachable by single hops (one letter changes) from a given word, we don't want to include the same word more than once.  Sets will take care of that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc20ad9-05be-4f81-bfe8-2c0cf9423c4a",
   "metadata": {},
   "source": [
    "One detail though. As a result of splitting and converting to a set, an empty string will have snuck into our set, and should be removed if found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca0831b-92ee-4f21-bcf0-416ce9336a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d104f9-f4b0-4d53-8514-f43f3ac8f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    words.remove('')\n",
    "except KeyError:\n",
    "    print(\"No empty string present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729eb4ad-e340-4902-9455-afdfdbc44f86",
   "metadata": {},
   "source": [
    "On a checklist, double check your lookup table of all 5757 words is indeed of that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f8d9b2-ef51-47a2-bb75-26494f699672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5757"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eebd108-3820-496e-83e9-8798a0b2d595",
   "metadata": {},
   "source": [
    "*The Stanford GraphBase: A Platform for Combinatorial Computing* is close to 600 pages and consists of numerous examples of \"literate programming* i.e. the kind of programming we do in Jupyter Notebooks.\n",
    "\n",
    "However, for this particular research project, that volume was not consulted.  Many of the results may nevertheless overlap.  Finding those connections is an exercise left to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61c068-60df-4eab-9cde-1b337bf7f743",
   "metadata": {},
   "source": [
    "The research project outlined above:\n",
    "\n",
    "\n",
    "* given \"only one letter different\" defines an edge between words, does our net of connected words encompass all the words?\n",
    "\n",
    "* if the answer to the above question is \"no\" then does the set consist of \"islands\" of words with definite boundaries?\n",
    "\n",
    "becomes interesting because it's easy to prove the answer is \"no\" to our first question.  We are able to find words that have no neighbors in the sense defined.  A good example would be \"spasm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706ff585-9954-4e93-a9b0-fd70ff409cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from five_land import initialize, roll_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8651d6-1fd9-4438-a35d-dbe3e4fa5367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(five_land.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793f955b-7376-450a-9156-e94182987441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5757\n"
     ]
    }
   ],
   "source": [
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba3ab46-e009-433e-ada3-3ef86589d292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = roll_alpha('spasm')\n",
    "neighbors  # no neighbors, empty set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7a2e0e-8a54-41df-b95e-501e3a231fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = roll_alpha('opera')\n",
    "neighbors  # likewise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc2b915-e24e-439d-9782-e1de03af556c",
   "metadata": {},
   "source": [
    "OK, so we know we have solitary \"word islands\" that consist of a single word.  Lets take another example, where the \"word island\" is larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e6b1da-5b36-4e63-b996-52de4a1d8e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logic\n",
      "yogic\n",
      "logic\n",
      "logic\n",
      "logic\n",
      "logic\n",
      "login\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'login', 'yogic'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = roll_alpha('logic', True)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25430b5c-813d-4caf-ab4d-175d0eb020f4",
   "metadata": {},
   "source": [
    "Turning on printing (2nd argument True) reveals how often the algorithm rediscovers the word itself, as roll_apha subsitutes a-z for each letter in turn, meaning it always rolls through itself at some point.  However, upon eliminating itself in the end (the last thing roll_apha does), the algorithm confines itself to providing neighbors one letter away, an no more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc5cf5-2b05-4094-9476-c5179efcb499",
   "metadata": {},
   "source": [
    "What we need next is an algorithm to keep growing the pool of words, starting from any pool, to find all words ultimately reachable in one letter jumps.  A single iteration of this algorithm will add neighbors for those currently in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2174872c-b640-4bda-b97a-80e578f66048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from five_land import fish_pond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e056ab48-318c-45af-860d-d1996ed2ba0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logic', 'login', 'yogic', 'yogis'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_neighbors = fish_pond(neighbors)\n",
    "new_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d03682-bdd0-465b-a146-ef050cd2914a",
   "metadata": {},
   "source": [
    "The crystallizing word \"logic\" is now back in the pool, as a neighbor of its neighbors, along with \"yogis\" which is two hops from \"logic\".\n",
    "\n",
    "We may continue cycling the growing list through fish_pond..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c458165d-1036-4d3a-8220-307c4c167d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logic', 'login', 'yogas', 'yogic', 'yogis'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = new_neighbors\n",
    "new_neighbors = fish_pond(neighbors)\n",
    "new_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2eacb0-cd5b-414d-98bc-211b2e5924d4",
   "metadata": {},
   "source": [
    "The set did not grow.  Here's an example of an island, whereon the words are reachable, one to another, by one-letter changes, until \"shores are reached\" and no more may be added.\n",
    "\n",
    "Now lets start with a more typical example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e68e00-ba22-45ce-9d4c-65623871ce25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    find all the words reachable from p by means \n",
      "    of *any number* of one letter legal word hops,\n",
      "    and stop when p stops growing.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from five_land import grow_pool\n",
    "print(grow_pool.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2258c458-12e5-4f9b-90a7-b57f41d71841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 105\n",
      "105 366\n",
      "366 816\n",
      "816 1346\n",
      "1346 1922\n",
      "1922 2487\n",
      "2487 3006\n",
      "3006 3451\n",
      "3451 3877\n",
      "3877 4200\n",
      "4200 4349\n",
      "4349 4426\n",
      "4426 4462\n",
      "4462 4480\n",
      "4480 4486\n",
      "4486 4489\n",
      "4489 4490\n",
      "4490 4492\n",
      "4492 4493\n",
      "4493 4493\n"
     ]
    }
   ],
   "source": [
    "final_set = grow_pool({\"caked\"}, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d392b01-c06e-4890-aeb4-e42becc58924",
   "metadata": {},
   "source": [
    "The numbers show by how many \"fish\" (legal five letter words) the pool is growing with each application of fish_pond( ).  The algorithm keeps cycling the growing pond through fish_pond until it stops growing. At that point, we know that no more \"fish\" will be found.\n",
    "\n",
    "What is the length of the final set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7944c443-2467-4dd9-9092-58ff0c851a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4493"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8aeeca-7dba-4965-93f0-6cd03b0a4b79",
   "metadata": {},
   "source": [
    "This turns out to be a central fracture in our semantic graph.  Any word in a set of 4493 words will find the others.  That's the giant island amidst an archipelago of smaller ones, down to the solitary islands such as \"spasm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "416d8e8d-5f74-4556-a0b4-777c7cf97f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words) - len(final_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0266717-d7d3-4602-9150-7c5b3e59c75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_land.never_reached = words - final_set\n",
    "len(five_land.never_reached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9594dc7-8102-48f6-856b-8c9042de2288",
   "metadata": {},
   "source": [
    "We learn that the archipelago consists of 1264 words (not necessarily all connected to each other), while the main island consists of 4493 words.  The total is 5757, the expected total\n",
    "\n",
    "A last reseach question for this Notebook is:  what is the make-up of this archipelago? How many islands and how big are they?\n",
    "\n",
    "Here's some background blogging about Donald Knuth's overall plan:\n",
    "[Knuth (Donald E. Knuth) two decades plan](https://blog.krybot.com/a?ID=01800-af2c69d8-40ba-4b02-9cdc-aca2c205be68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcc154f7-6110-45d8-9a67-e68d53df7249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'five_land' from '/Users/mac/Documents/elite_school/five_land.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import five_land\n",
    "from imp import reload\n",
    "reload(five_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a59d4213-57c5-48be-a93f-0cba709ee6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5757\n"
     ]
    }
   ],
   "source": [
    "from five_land import survey\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7017c64d-e5a1-4344-b2f5-573caa1aa774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 671,\n",
       "  7: 42,\n",
       "  2: 206,\n",
       "  3: 126,\n",
       "  15: 45,\n",
       "  6: 24,\n",
       "  4: 52,\n",
       "  5: 30,\n",
       "  24: 24,\n",
       "  19: 19,\n",
       "  17: 17,\n",
       "  8: 8},\n",
       " 24,\n",
       " 'duffs',\n",
       " set())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd7e26e-381c-4821-889c-c90243ab7f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 671,\n",
       "  7: 42,\n",
       "  2: 206,\n",
       "  3: 126,\n",
       "  15: 45,\n",
       "  6: 24,\n",
       "  4: 52,\n",
       "  5: 30,\n",
       "  24: 24,\n",
       "  19: 19,\n",
       "  17: 17,\n",
       "  8: 8},\n",
       " 24,\n",
       " 'duffs',\n",
       " {'biffs',\n",
       "  'biffy',\n",
       "  'boffo',\n",
       "  'boffs',\n",
       "  'buffa',\n",
       "  'buffo',\n",
       "  'buffs',\n",
       "  'cuffs',\n",
       "  'daffy',\n",
       "  'doffs',\n",
       "  'duffs',\n",
       "  'huffs',\n",
       "  'huffy',\n",
       "  'jiffs',\n",
       "  'jiffy',\n",
       "  'miffs',\n",
       "  'muffs',\n",
       "  'puffs',\n",
       "  'puffy',\n",
       "  'ruffs',\n",
       "  'taffy',\n",
       "  'tiffs',\n",
       "  'toffs',\n",
       "  'toffy'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa930b7-6565-40fb-ae30-7fa8255747ec",
   "metadata": {},
   "source": [
    "What this survey tells us is a lot of 3- and 2-word islands, 42 and 103 respectively, involving 126 and 206 total words. One island consists of 24 words, and is the biggest aside from the Big Island of 4493. \n",
    "\n",
    "Islands do not have overlapping membership.  The item \"15: 45\", for example, suggests 45 words participate in three disjoint subnets of 15 words each.\n",
    "\n",
    "Two words on the same island will have a path between them, of only one-letter change hops.  Two words on different islands, never will.\n",
    "\n",
    "To figure out whether any two five-letter words have a path of edge hops between them, it should be sufficent to discover whether they on on the same island.  If both are on an island of size greater than 24, then we know both are on the main island.  Otherwise, within very few iterations, it should be possible to decide if they're on the same smaller island."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c0141ce-1c24-47f4-92c6-6d0f33b68e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5757\n"
     ]
    }
   ],
   "source": [
    "from five_land import path_exists\n",
    "five_land.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c3158e9-3699-45dd-94d9-16fc81faa8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_exists(\"caked\", \"fluid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "819e0082-45d5-4a12-a064-8e8520d138fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both on big island\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_exists(\"hello\", \"norms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4d8bef-5269-445b-b3eb-a4c1e537a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same small island\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_exists(\"logic\", \"yogis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915f338-da82-4eb0-8d1b-db76db75d14b",
   "metadata": {},
   "source": [
    "### Wordle\n",
    "\n",
    "Check the [Project Page](ADS_project_1.ipynb) for links between Five Letter Land and Wordle.  The 5757 list we're using is reportedly much larger than the one hard-coded into Wordle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122bf30-50fa-4478-bf9c-ff7231ed6ff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pi Day (3 - 14)\n",
    "\n",
    "More projects suggest themselves around Pi Day.\n",
    "\n",
    "Here's a link to a friendly repo:\n",
    "\n",
    "[Pi Day at Python5](https://nbviewer.org/github/4dsolutions/Python5/blob/master/Pi%20Day%20Fun.ipynb)\n",
    "\n",
    "And a friendly repl:\n",
    "\n",
    "[pi_day on Repl.it](https://replit.com/@kurner/piday#main.py)\n",
    "\n",
    "The Ramanujan expression for $(1/\\pi)$ is also taken up in [Exercises](Exercises.ipynb) here at our EliteSchool.\n",
    "\n",
    "From Python Docs:  [itertools library](https://docs.python.org/3/library/itertools.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc06f3-7033-4245-a670-bfd5e952079a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
